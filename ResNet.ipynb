{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e4bea7f-3937-4d32-b7b6-0341dec4ab7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "from torchvision.utils import make_grid\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, jaccard_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7dede60-2298-41ba-9b25-29d0141c5574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "023224f2-3f60-402f-8bff-33991207c003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Apr  9 11:12:19 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 528.33       Driver Version: 528.33       CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   48C    P8     4W /  50W |     89MiB /  4096MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2388    C+G   ...661.62\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A      5052    C+G   ...e\\PhoneExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      7108    C+G   ...8wekyb3d8bbwe\\Cortana.exe    N/A      |\n",
      "|    0   N/A  N/A     11776    C+G   ...n1h2txyewy\\SearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A     13248    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     15696    C+G   ...ropbox\\Client\\Dropbox.exe    N/A      |\n",
      "|    0   N/A  N/A     16400    C+G   ...661.62\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     18124    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     22552    C+G   ...2gh52qy24etm\\Nahimic3.exe    N/A      |\n",
      "|    0   N/A  N/A     27592    C+G   ...v1g1gvanyjgm\\WhatsApp.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffeae91e-fa23-4398-bcbc-eb4dd9fa1bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e8bf648-4cb2-4919-be42-f7e731cb231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrainTumorDataset(Dataset):\n",
    "  def __init__(self, images, labels):\n",
    "    # images\n",
    "    self.X = images\n",
    "    # labels\n",
    "    self.y = labels\n",
    "    \n",
    "    # Transformation for converting original image array to an image and then convert it to a tensor\n",
    "    self.transform = transforms.Compose([transforms.ToPILImage(),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    # Transformation for converting original image array to an image, rotate it randomly between -45 degrees and 45 degrees, and then convert it to a tensor\n",
    "    self.transform1 = transforms.Compose([\n",
    "        transforms.ToPILImage(),                                          \n",
    "        transforms.RandomRotation(45),\n",
    "        transforms.ToTensor()                                 \n",
    "    ])\n",
    "\n",
    "    # Transformation for converting original image array to an image, rotate it randomly between -90 degrees and 90 degrees, and then convert it to a tensor\n",
    "    self.transform2 = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomRotation(90),\n",
    "        transforms.ToTensor()                                  \n",
    "    ])\n",
    "\n",
    "    # Transformation for converting original image array to an image, rotate it randomly between -120 degrees and 120 degrees, and then convert it to a tensor\n",
    "    self.transform3 = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomRotation(120),\n",
    "        transforms.ToTensor()                                  \n",
    "    ])\n",
    "\n",
    "    # Transformation for converting original image array to an image, rotate it randomly between -180 degrees and 180 degrees, and then convert it to a tensor\n",
    "    self.transform4 = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomRotation(180),\n",
    "        transforms.ToTensor()                                \n",
    "    ])\n",
    "\n",
    "    # Transformation for converting original image array to an image, rotate it randomly between -270 degrees and 270 degrees, and then convert it to a tensor\n",
    "    self.transform5 = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomRotation(270),\n",
    "        transforms.ToTensor()                                \n",
    "    ])\n",
    "\n",
    "    # Transformation for converting original image array to an image, rotate it randomly between -300 degrees and 300 degrees, and then convert it to a tensor\n",
    "    self.transform6 = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomRotation(300),\n",
    "        transforms.ToTensor()                               \n",
    "    ])\n",
    "\n",
    "    # Transformation for converting original image array to an image, rotate it randomly between -330 degrees and 330 degrees, and then convert it to a tensor\n",
    "    self.transform7 = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomRotation(330),\n",
    "        transforms.ToTensor()                                 \n",
    "    ])\n",
    "\n",
    "  def __len__(self):\n",
    "    # return length of image samples\n",
    "    return len(self.X)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    # perform transformations on one instance of X\n",
    "    # Original image as a tensor\n",
    "    data = self.transform(self.X[idx])\n",
    "\n",
    "    # Augmented image at 45 degrees as a tensor\n",
    "    aug45 = self.transform1(self.X[idx])\n",
    "\n",
    "    # Augmented image at 90 degrees as a tensor\n",
    "    aug90 = self.transform2(self.X[idx])\n",
    "\n",
    "    # Augmented image at 120 degrees as a tensor\n",
    "    aug120 = self.transform3(self.X[idx])\n",
    "\n",
    "    # Augmented image at 180 degrees as a tensor\n",
    "    aug180 = self.transform4(self.X[idx])\n",
    "\n",
    "    # Augmented image at 270 degrees as a tensor\n",
    "    aug270 = self.transform5(self.X[idx])\n",
    "\n",
    "    # Augmented image at 300 degrees as a tensor\n",
    "    aug300 = self.transform6(self.X[idx])\n",
    "\n",
    "    # Augmented image at 330 degrees as a tensor\n",
    "    aug330 = self.transform7(self.X[idx])      \n",
    "    \n",
    "    # store the transformed images in a list\n",
    "    new_batch = [data, aug45, aug90, aug120, aug180, aug270, aug300, aug330]\n",
    "\n",
    "    # one-hot encode the labels\n",
    "    labels = torch.zeros(4, dtype=torch.float32)\n",
    "    labels[int(self.y[idx])] = 1.0\n",
    "\n",
    "    new_labels = [labels, labels, labels, labels, labels, labels, labels, labels]\n",
    "\n",
    "    # 8 augmented images and corresponding labels per sample will be returned\n",
    "    return (torch.stack(new_labels), torch.stack(new_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "257e8253-e318-4db5-ab32-767dea4eec69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "\n",
    "train_dataset = datasets.ImageFolder('dataset/dataset/Training')\n",
    "test_dataset = datasets.ImageFolder('dataset/dataset/Testing')\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a7e5320-3770-4003-bf49-1f1e61bdf3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = []\n",
    "yt = []\n",
    "features = None\n",
    "labels = None\n",
    "label = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0757b8a9-879c-46aa-b69d-b6e0be008ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for features,labels in train_dataset:\n",
    "  Xt.append(features)\n",
    "  yt.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0151bc63-fc0f-48f9-94ec-9864300b019b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70 % training, 15% validating, 15% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xt, yt, test_size=0.3, shuffle=True)  # 70% training, 30% testing\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test, test_size=0.5, shuffle=True)  # split testing set into 50% validation , 50% testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04c65458-5481-4386-90e6-1340bdf12277",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = None\n",
    "yt = None\n",
    "features = None\n",
    "labels = None\n",
    "label = None\n",
    "training_data = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e6f95d6-2d83-408d-a06a-ef6bd59a1057",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = BrainTumorDataset(X_train, y_train)\n",
    "valid_set = BrainTumorDataset(X_valid, y_valid)\n",
    "test_set = BrainTumorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a224417c-27a2-49da-89d4-787512af2ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 3998\n",
      "Number of validation samples: 857\n",
      "Number of testing samples: 857\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training samples: {len(X_train)}\")\n",
    "print(f\"Number of validation samples: {len(X_valid)}\")\n",
    "print(f\"Number of testing samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94eacf65-b18d-41f5-8dc8-db45fa563842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of augmented training samples: 31984\n",
      "Number of augmented validation samples: 6856\n",
      "Number of augmented testing samples: 6856\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of augmented training samples: {len(X_train) * 8}\")\n",
    "print(f\"Number of augmented validation samples: {len(X_valid)* 8}\")\n",
    "print(f\"Number of augmented testing samples: {len(X_test)* 8}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18fe8dd1-13d8-41d5-82db-e13b5a5a47b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = DataLoader(train_set, batch_size=4, shuffle=True, pin_memory=True, num_workers=8)\n",
    "valid_gen = DataLoader(valid_set, batch_size=4, shuffle=True, pin_memory=True, num_workers=8)\n",
    "test_gen = DataLoader(test_set, batch_size=10, shuffle=True, pin_memory=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13fe67ab-88d7-484c-8972-cd6e7cce1c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_name = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b93cf5c-cc0b-456b-b7cf-98f192c2e2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bharath D\\.conda\\envs\\env-2\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Bharath D\\.conda\\envs\\env-2\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to C:\\Users\\Bharath D/.cache\\torch\\hub\\checkpoints\\resnet50-0676ba61.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0094b11163124b2e81e39cdf75c04047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (1): SELU()\n",
       "    (2): Dropout(p=0.4, inplace=False)\n",
       "    (3): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (4): SELU()\n",
       "    (5): Dropout(p=0.4, inplace=False)\n",
       "    (6): Linear(in_features=2048, out_features=4, bias=True)\n",
       "    (7): LogSigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate transfer learning model\n",
    "resnet_model = models.resnet50(pretrained=True)\n",
    "\n",
    "# set all paramters as trainable\n",
    "for param in resnet_model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# get input of fc layer\n",
    "n_inputs = resnet_model.fc.in_features\n",
    "\n",
    "# redefine fc layer / top layer/ head for our classification problem\n",
    "resnet_model.fc = nn.Sequential(nn.Linear(n_inputs, 2048),\n",
    "                                nn.SELU(),\n",
    "                                nn.Dropout(p=0.4),\n",
    "                                nn.Linear(2048, 2048),\n",
    "                                nn.SELU(),\n",
    "                                nn.Dropout(p=0.4),\n",
    "                                nn.Linear(2048, 4),\n",
    "                                nn.LogSigmoid())\n",
    "\n",
    "# set all paramters of the model as trainable\n",
    "for name, child in resnet_model.named_children():\n",
    "  for name2, params in child.named_parameters():\n",
    "    params.requires_grad = True\n",
    "\n",
    "# set model to run on GPU or CPU absed on availibility\n",
    "resnet_model.to(device)\n",
    "\n",
    "# print the trasnfer learning NN model's architecture\n",
    "resnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e267d0c1-9ff1-4bdc-8bf7-806473acacd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "# if GPU is available set loss function to use GPU\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(resnet_model.parameters(), momentum=0.9, lr=3e-4)\n",
    "\n",
    "# number of training iterations\n",
    "epochs = 30\n",
    "\n",
    "# empty lists to store losses and accuracies\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_correct = []\n",
    "test_correct = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff1e866e-4a68-444f-8bc6-038851d375f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='bt_resnet50_ckpt_v2.pth.tar'):\n",
    "    torch.save(state, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b081d37-a99d-49c0-b742-c0d6670c7632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set training start time\n",
    "start_time = time.time()\n",
    "\n",
    "# set best_prec loss value as 2 for checkpoint threshold\n",
    "best_prec1 = 2\n",
    "\n",
    "# empty batch variables\n",
    "b = None\n",
    "train_b = None\n",
    "test_b = None\n",
    "\n",
    "# start training\n",
    "for i in range(epochs):\n",
    "    # empty training correct and test correct counter as 0 during every iteration\n",
    "    trn_corr = 0\n",
    "    tst_corr = 0\n",
    "    \n",
    "    # set epoch's starting time\n",
    "    e_start = time.time()\n",
    "    \n",
    "    # train in batches\n",
    "    for b, (y, X) in enumerate(train_gen):\n",
    "        # set label as cuda if device is cuda\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # forward pass image sample\n",
    "        y_pred = resnet_model(X.view(-1, 3, 512, 512))\n",
    "        # calculate loss\n",
    "        loss = criterion(y_pred.float(), torch.argmax(y.view(32, 4), dim=1).long())\n",
    "\n",
    "        # get argmax of predicted tensor, which is our label\n",
    "        predicted = torch.argmax(y_pred, dim=1).data\n",
    "        # if predicted label is correct as true label, calculate the sum for samples\n",
    "        batch_corr = (predicted == torch.argmax(y.view(32, 4), dim=1)).sum()\n",
    "        # increment train correct with correcly predicted labels per batch\n",
    "        trn_corr += batch_corr\n",
    "        \n",
    "        # set optimizer gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "        # back propagate with loss\n",
    "        loss.backward()\n",
    "        # perform optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "    # set epoch's end time\n",
    "    e_end = time.time()\n",
    "    # print training metrics\n",
    "    print(f'Epoch {(i+1)} Batch {(b+1)*4}\\nAccuracy: {trn_corr.item()*100/(4*8*b):2.2f} %  Loss: {loss.item():2.4f}  Duration: {((e_end-e_start)/60):.2f} minutes') # 4 images per batch * 8 augmentations per image * batch length\n",
    "\n",
    "    # some metrics storage for visualization\n",
    "    train_b = b\n",
    "    train_losses.append(loss)\n",
    "    train_correct.append(trn_corr)\n",
    "\n",
    "    X, y = None, None\n",
    "\n",
    "    # validate using validation generator\n",
    "    # do not perform any gradient updates while validation\n",
    "    with torch.no_grad():\n",
    "        for b, (y, X) in enumerate(valid_gen):\n",
    "            # set label as cuda if device is cuda\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # forward pass image\n",
    "            y_val = resnet_model(X.view(-1, 3, 512, 512))\n",
    "\n",
    "            # get argmax of predicted tensor, which is our label\n",
    "            predicted = torch.argmax(y_val, dim=1).data\n",
    "\n",
    "            # increment test correct with correcly predicted labels per batch\n",
    "            tst_corr += (predicted == torch.argmax(y.view(32, 4), dim=1)).sum()\n",
    "\n",
    "    # get loss of validation set\n",
    "    loss = criterion(y_val.float(), torch.argmax(y.view(32, 4), dim=1).long())\n",
    "    # print validation metrics\n",
    "    print(f'Validation Accuracy {tst_corr.item()*100/(4*8*b):2.2f} Validation Loss: {loss.item():2.4f}\\n')\n",
    "\n",
    "    # if current validation loss is less than previous iteration's validatin loss create and save a checkpoint\n",
    "    is_best = loss < best_prec1\n",
    "    best_prec1 = min(loss, best_prec1)\n",
    "    save_checkpoint({\n",
    "            'epoch': i + 1,\n",
    "            'state_dict': resnet_model.state_dict(),\n",
    "            'best_prec1': best_prec1,\n",
    "        }, is_best)\n",
    "\n",
    "    # some metrics storage for visualization\n",
    "    test_b  = b\n",
    "    test_losses.append(loss)\n",
    "    test_correct.append(tst_corr)\n",
    "\n",
    "# set total training's end time\n",
    "end_time = time.time() - start_time    \n",
    "\n",
    "# print training summary\n",
    "print(\"\\nTraining Duration {:.2f} minutes\".format(end_time/60))\n",
    "print(\"GPU memory used : {} kb\".format(torch.cuda.memory_allocated()))\n",
    "print(\"GPU memory cached : {} kb\".format(torch.cuda.memory_cached()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3e6008-c2e8-4fb1-b597-9e98c6d397e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39e547f-fcf0-4f84-83a6-37ece865a47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet_model.state_dict(), '/content/drive/My Drive/bt_resnet50_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b8d29a-5fee-4b8e-9c62-1a8b0c00ceab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Validation accuracy: {test_correct[-1].item()*100/(test_b*8*4):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6587e2-6a6e-4ac2-a9d0-4bc266cf11fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(test_losses, label='Validation loss')\n",
    "plt.title('Loss Metrics')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79f854c-f85e-450d-a637-df23e9ed9e1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
